{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries, including TensorFlow, Keras, NumPy, Pandas, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, Embedding, LSTM, Bidirectional, concatenate, \n",
    "                                     RandomFlip, RandomRotation, Rescaling, Conv2D, GlobalAveragePooling2D, TextVectorization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import re\n",
    "import string\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Inspect Data\n",
    "Load the dataset and inspect the first few rows to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humour           int64\n",
      "sarcasm          int64\n",
      "offensive       object\n",
      "motivational     int64\n",
      "dtype: object\n",
      "   humour  sarcasm offensive  motivational\n",
      "0       3        1         0             0\n",
      "1       0        1         0             1\n",
      "2       2        0         0             0\n",
      "3       2        2         2             1\n",
      "4       3        3         2             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_27080\\1084920341.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Tensorquest/memotion_dataset_7k/labels.csv\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df = df.replace({\n",
    "    'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 2, 'hilarious': 3},\n",
    "    'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 2, 'very_twisted': 3},\n",
    "    'offensive': {'not_offensive': 0, 'slightly_offensive': 1, 'very_offensive': 2},\n",
    "    'motivational': {'not_motivational': 0, 'motivational': 1},\n",
    "    'overall_sentiment': {'very_negative': 0, 'negative': 1, 'neutral': 2, 'positive': 3, 'very_positive': 4}\n",
    "\n",
    "    \n",
    "})\n",
    "# ...after encoding and before splitting...\n",
    "print(df[['humour', 'sarcasm', 'offensive', 'motivational']].dtypes)\n",
    "print(df[['humour', 'sarcasm', 'offensive', 'motivational']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_name  \\\n",
       "0           0   image_1.jpg   \n",
       "1           1  image_2.jpeg   \n",
       "2           2   image_3.JPG   \n",
       "3           3   image_4.png   \n",
       "4           4   image_5.png   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3              10 Year Challenge - Sweet Dee Edition   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                      text_corrected  humour  sarcasm  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...       3        1   \n",
       "1  The best of #10 YearChallenge! Completed in le...       0        1   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...       2        0   \n",
       "3              10 Year Challenge - Sweet Dee Edition       2        2   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...       3        3   \n",
       "\n",
       "  offensive  motivational  overall_sentiment  \n",
       "0         0             0                  4  \n",
       "1         0             1                  4  \n",
       "2         0             0                  3  \n",
       "3         2             1                  3  \n",
       "4         2             0                  2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Missing Values\n",
    "Check for missing values and drop or fill them as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for each column is ,\n",
      "  Unnamed: 0           0\n",
      "image_name           0\n",
      "text_ocr             0\n",
      "text_corrected       0\n",
      "humour               0\n",
      "sarcasm              0\n",
      "offensive            0\n",
      "motivational         0\n",
      "overall_sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values for each column is ,\\n \", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing\n",
    "Load images, resize them, and normalize pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\envs\\tfenv\\lib\\site-packages\\PIL\\Image.py:1043: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "width, height = 100, 100\n",
    "X = []\n",
    "for i in range(df.shape[0]):\n",
    "    try:\n",
    "        path = '../Tensorquest/memotion_dataset_7k/images/' + df.iloc[i]['image_name']\n",
    "        img = image.load_img(path, target_size=(width, height, 3) )\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "        X.append(img)\n",
    "    except (FileNotFoundError, OSError):\n",
    "        continue\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing target variables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = df[['humour', 'sarcasm', 'offensive', 'motivational']].iloc[:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Standardize Text ---\n",
    "def standardize_text(data):\n",
    "    data = data.apply(lambda x: x.lower())\n",
    "    data = data.apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "    data = data.apply(lambda x: re.sub(r'.com', '', x, flags=re.MULTILINE))\n",
    "    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    return data\n",
    "df['text_corrected'] = standardize_text(df['text_corrected'].astype(str)).iloc[:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the text data\n",
    "df = df.replace({\n",
    "    'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 2, 'hilarious': 3},\n",
    "    'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 2, 'very_twisted': 3},\n",
    "    'offensive': {'not_offensive': 0, 'slightly_offensive': 1, 'very_offensive': 2},\n",
    "    'motivational': {'not_motivational': 0, 'motivational': 1},\n",
    "    'overall_sentiment': {'very_negative': 0, 'negative': 1, 'neutral': 2, 'positive': 3, 'very_positive': 4}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'slight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- 6. Split Dataset (images, text, targets together to avoid misalignment) ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test, X_text_train, X_text_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      3\u001b[0m     X, Y, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_corrected\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_test)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'slight'"
     ]
    }
   ],
   "source": [
    "# --- 6. Split Dataset (images, text, targets together to avoid misalignment) ---\n",
    "X_train, X_test, y_train, y_test, X_text_train, X_text_test = train_test_split(\n",
    "    X, Y, df['text_corrected'].values, test_size=0.2, random_state=30)\n",
    "\n",
    "y_train = np.array(y_train).astype('float32')\n",
    "y_test = np.array(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Text Vectorization ---\n",
    "vocab_size = 100000\n",
    "sequence_length = 50\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length,\n",
    "    standardize=\"lower_and_strip_punctuation\"\n",
    ")\n",
    "vectorize_layer.adapt(df['text_corrected'].values)\n",
    "X_text_train = vectorize_layer(X_text_train)\n",
    "X_text_test = vectorize_layer(X_text_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'slight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m X_text_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_text_train)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_text_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_text_test)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_test)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'slight'"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "X_text_train = np.array(X_text_train).astype('int32')\n",
    "X_text_test = np.array(X_text_test).astype('int32')\n",
    "y_train = np.array(y_train).astype('float32')\n",
    "y_test = np.array(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 8. Data Augmentation ---\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip('horizontal'),\n",
    "    RandomRotation(0.2)\n",
    "])\n",
    "\n",
    "# what this does is randomly flips the models and randomly roatets the images so as to prevent overfitting , it is roattwed by 20% meaning 72 degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Build Base Image Model ---\n",
    "base_model_1 = tf.keras.applications.ResNet50(input_shape=(100, 100, 3), include_top=False, weights='imagenet')\n",
    "base_model_2 = tf.keras.applications.VGG16(input_shape=(100, 100, 3), include_top=False, weights='imagenet')\n",
    "base_model_1.trainable = False\n",
    "base_model_2.trainable = False\n",
    "\n",
    "image_input = Input(shape=(100, 100, 3), name='image_input')\n",
    "x = data_augmentation(image_input)\n",
    "x = tf.keras.applications.resnet50.preprocess_input(x)\n",
    "x1 = base_model_1(x, training=False)\n",
    "x2 = base_model_2(x, training=False)\n",
    "x1 = Conv2D(2048, kernel_size=2, padding='valid')(x1)\n",
    "x1 = Dense(512)(x1)\n",
    "x2 = Dense(512)(x2)\n",
    "x = concatenate([x1, x2])\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2, name='dropout_layer')(x)\n",
    "image_model = Model(inputs=image_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Build Text Model ---\n",
    "text_input = Input(shape=(sequence_length,), dtype=tf.int32, name='text')\n",
    "embedding_dim = 32\n",
    "y = Embedding(vocab_size, embedding_dim, name=\"embedding\")(text_input)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Bidirectional(LSTM(256, activation='relu', return_sequences=True))(y)\n",
    "y = Bidirectional(LSTM(128, activation='relu'))(y)\n",
    "y = Dense(1024, activation='relu')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "text_model = Model(inputs=text_input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. Combine Models ---\n",
    "combined = concatenate([image_model.output, text_model.output])\n",
    "combined = Dense(512, activation='relu')(combined)\n",
    "combined = Dropout(0.5)(combined)\n",
    "output = Dense(4, activation='linear', name=\"semantic_output\")(combined)\n",
    "combined_model = Model(inputs=[image_model.input, text_model.input], outputs=output)\n",
    "combined_model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float32\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'> <dtype: 'int64'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27080\\830382634.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_text_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_text_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "print(type(X_train), X_train.dtype)\n",
    "print(type(X_text_train), X_text_train.dtype)\n",
    "print(type(y_train), y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubh\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m      3\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_text_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_text_test\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfenv\\lib\\site-packages\\optree\\ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid dtype: object"
     ]
    }
   ],
   "source": [
    "# --- 12. Train Model ---\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "history = combined_model.fit(\n",
    "    {'image_input': X_train, 'text': X_text_train},\n",
    "    y_train,\n",
    "    validation_data=({'image_input': X_test, 'text': X_text_test}, y_test),\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 13. Plot Training History ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model Mean Absolute Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 14. Evaluate Model ---\n",
    "combined_predictions = combined_model.predict({'image_input': X_test, 'text': X_text_test})\n",
    "mae_humor_combined = mean_absolute_error(y_test['humour'], combined_predictions[:, 0])\n",
    "mae_sarcasm_combined = mean_absolute_error(y_test['sarcasm'], combined_predictions[:, 1])\n",
    "mae_offense_combined = mean_absolute_error(y_test['offensive'], combined_predictions[:, 2])\n",
    "mae_motivation_combined = mean_absolute_error(y_test['motivational'], combined_predictions[:, 3])\n",
    "print(f\"MAE for Humor (Combined): {mae_humor_combined}\")\n",
    "print(f\"MAE for Sarcasm (Combined): {mae_sarcasm_combined}\")\n",
    "print(f\"MAE for Offense (Combined): {mae_offense_combined}\")\n",
    "print(f\"MAE for Motivation (Combined): {mae_motivation_combined}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classification reports and confusion matrices\n",
    "for i, label in enumerate(['humour', 'sarcasm', 'offensive', 'motivational']):\n",
    "    print(f\"Classification Report for {label.capitalize()}:\")\n",
    "    print(classification_report(y_test[label], np.round(combined_predictions[:, i])))\n",
    "    conf_matrix = confusion_matrix(y_test[label], np.round(combined_predictions[:, i]))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {label.capitalize()}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfenv]",
   "language": "python",
   "name": "conda-env-tfenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
