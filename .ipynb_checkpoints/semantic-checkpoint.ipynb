{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, Embedding, LSTM, Bidirectional, concatenate)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_name  \\\n",
       "0           0   image_1.jpg   \n",
       "1           1  image_2.jpeg   \n",
       "2           2   image_3.JPG   \n",
       "3           3   image_4.png   \n",
       "4           4   image_5.png   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3              10 Year Challenge - Sweet Dee Edition   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                      text_corrected      humour  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n",
       "1  The best of #10 YearChallenge! Completed in le...   not_funny   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n",
       "3              10 Year Challenge - Sweet Dee Edition  very_funny   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n",
       "\n",
       "           sarcasm       offensive      motivational overall_sentiment  \n",
       "0          general   not_offensive  not_motivational     very_positive  \n",
       "1          general   not_offensive      motivational     very_positive  \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive  \n",
       "3  twisted_meaning  very_offensive      motivational          positive  \n",
       "4     very_twisted  very_offensive  not_motivational           neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Tensorquest/memotion_dataset_7k/labels.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           False\n",
       "image_name           False\n",
       "text_ocr              True\n",
       "text_corrected        True\n",
       "humour               False\n",
       "sarcasm              False\n",
       "offensive            False\n",
       "motivational         False\n",
       "overall_sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           False\n",
       "image_name           False\n",
       "text_ocr             False\n",
       "text_corrected       False\n",
       "humour               False\n",
       "sarcasm              False\n",
       "offensive            False\n",
       "motivational         False\n",
       "overall_sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_18992\\1300552629.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({\n"
     ]
    }
   ],
   "source": [
    "df = df.replace({\n",
    "    'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 2, 'hilarious': 3},\n",
    "    'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 2, 'very_twisted': 3},\n",
    "    'offensive': {'not_offensive': 0, 'slightly_offensive': 1, 'very_offensive': 2},\n",
    "    'motivational': {'not_motivational': 0, 'motivational': 1},\n",
    "    'overall_sentiment': {'very_negative': 0, 'negative': 1, 'neutral': 2, 'positive': 3, 'very_positive': 4}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_name  \\\n",
       "0           0   image_1.jpg   \n",
       "1           1  image_2.jpeg   \n",
       "2           2   image_3.JPG   \n",
       "3           3   image_4.png   \n",
       "4           4   image_5.png   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3              10 Year Challenge - Sweet Dee Edition   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                      text_corrected  humour  sarcasm  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...       3        1   \n",
       "1  The best of #10 YearChallenge! Completed in le...       0        1   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...       2        0   \n",
       "3              10 Year Challenge - Sweet Dee Edition       2        2   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...       3        3   \n",
       "\n",
       "  offensive  motivational  overall_sentiment  \n",
       "0         0             0                  4  \n",
       "1         0             1                  4  \n",
       "2         0             0                  3  \n",
       "3         2             1                  3  \n",
       "4         2             0                  2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_class(row):\n",
    "    if row['humour'] > 0:\n",
    "        return 1  # Humorous\n",
    "    elif row['sarcasm'] > 0:\n",
    "        return 0  # Sarcastic\n",
    "    elif row['motivational'] > 0:\n",
    "        return 2  # Motivational\n",
    "    elif row['offensive'] > 0:\n",
    "        return 3  # Offensive Meme\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████▌   | 6531/6830 [01:23<00:03, 97.61it/s]C:\\Users\\shubh\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 6830/6830 [01:26<00:00, 78.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "width = 100\n",
    "height = 100\n",
    "X = []  \n",
    "for i in tqdm(range(df.shape[0])):  \n",
    "    try:\n",
    "        path = 'memotion_dataset_7k/images/' + df.iloc[i]['image_name']\n",
    "        img = image.load_img(path, target_size=(width, height, 3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        X.append(img)\n",
    "    except (FileNotFoundError, OSError) as e:\n",
    "        print(f\"Skipping image {df.iloc[i]['image_name']} due to error: {e}\")\n",
    "\n",
    "X = np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6830, 100, 100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLITTING OF DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.iloc[:,2:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE AUGMENATATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, Rescaling\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip('horizontal'),\n",
    "    RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "rescale = Rescaling(1./127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "base_model_1 = tf.keras.applications.ResNet50(input_shape=X[0].shape, include_top=False, weights='imagenet')\n",
    "base_model_2 = tf.keras.applications.VGG16(input_shape=X[0].shape, include_top=False, weights='imagenet')\n",
    "base_model_1.trainable = False\n",
    "base_model_2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "\n",
    "image_input = tf.keras.Input(shape=(100, 100, 3), name='image_input')\n",
    "image_layers = data_augmentation(image_input)\n",
    "image_layers = preprocess_input(image_layers)\n",
    "layer_bm_1 = base_model_1(image_input, training=False)\n",
    "layer_bm_1 = Conv2D(2048, kernel_size=2, padding='valid')(layer_bm_1)\n",
    "layer_bm_1 = Dense(512)(layer_bm_1)\n",
    "layer_bm_2 = base_model_2(image_input, training=False)\n",
    "layer_bm_2 = Dense(512)(layer_bm_2)\n",
    "layers = tf.keras.layers.concatenate([layer_bm_1, layer_bm_2])\n",
    "image_layers = GlobalAveragePooling2D()(layers)\n",
    "image_layers = Dropout(0.2, name='dropout_layer')(image_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT MODELLINGabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(data):\n",
    "    data = data.apply(lambda x: x.lower())  # Convert text to lowercase\n",
    "    data = data.apply(lambda x: re.sub(r'\\d+', '', x))  # Remove digits\n",
    "    data = data.apply(lambda x: re.sub(r'.com', '', x, flags=re.MULTILINE))  # Remove '.com'\n",
    "    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))  # Remove punctuation\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_corrected'] = standardization(df['text_corrected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[['humour', 'sarcasm', 'offensive', 'motivational']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "\n",
    "vocab_size = 100000\n",
    "sequence_length = 50\n",
    "embedding_dim = 32\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = np.asarray(df['text_corrected'])\n",
    "vectorize_layer.adapt(tf.convert_to_tensor(text_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(df['text_corrected'], Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = Input(shape=(None,), dtype=tf.string, name='text')\n",
    "text_layers = vectorize_layer(text_input)  # Vectorization of input text\n",
    "text_layers = Embedding(vocab_size, embedding_dim, name=\"embedding\")(text_layers)  # Embedding layer\n",
    "text_layers = Dropout(0.5)(text_layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layering\n",
    "from tensorflow.keras.layers import Reshape, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Bidirectional, LSTM\n",
    "\n",
    "# Assuming text_layers is the output of previous layers and is 2D at this point\n",
    "text_layers = Dense(2048, activation=\"relu\")(text_layers)\n",
    "text_layers = Dropout(0.5)(text_layers)\n",
    "\n",
    "# Reshape to 3D for Conv1D (adding a sequence length of 1)\n",
    "text_layers = Reshape((1, 2048))(text_layers)\n",
    "\n",
    "# Convolutional layers for feature extraction\n",
    "text_layers = Conv1D(128, 3, padding=\"same\", activation=\"relu\", strides=1)(text_layers)\n",
    "text_layers = Conv1D(128, 3, padding=\"same\", activation=\"relu\", strides=1)(text_layers)\n",
    "\n",
    "# Pooling and dense layers\n",
    "text_layers = GlobalMaxPooling1D()(text_layers)\n",
    "text_layers = Dense(1024, activation=\"relu\")(text_layers)\n",
    "text_layers = Dropout(0.5)(text_layers)\n",
    "\n",
    "# Reshape to add sequence dimension for LSTM layers\n",
    "text_layers = Reshape((1, 1024))(text_layers)\n",
    "\n",
    "# Bidirectional LSTM layers\n",
    "text_layers = Bidirectional(LSTM(256, activation='relu', return_sequences=True))(text_layers)\n",
    "text_layers = Bidirectional(LSTM(128, activation='relu'))(text_layers)\n",
    "\n",
    "# Output layer for semantic scaling\n",
    "output = Dense(4, activation='linear', name=\"semantic_output\")(text_layers)\n",
    "\n",
    "# Final model definition\n",
    "model = tf.keras.Model(inputs=[text_input], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5464,)\n",
      "(5464, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_text_train.shape)  \n",
    "print(y_text_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'slight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18992\\1104542896.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_text_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_text_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_text_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_text_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0my_text_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_text_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my_text_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_text_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'slight'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "X_text_train = np.array(X_text_train, dtype=str)\n",
    "X_text_test = np.array(X_text_test, dtype=str)\n",
    "\n",
    "y_text_train = np.array(y_text_train, dtype=np.float32)\n",
    "y_text_test = np.array(y_text_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mtext_input, outputs\u001b[38;5;241m=\u001b[39moutput)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_text_train, y_text_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_text_test, y_text_test))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optree\\ops.py:752\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    750\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    751\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treespec\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;28mmap\u001b[39m(func, \u001b[38;5;241m*\u001b[39mflat_args))\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid dtype: object"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=text_input, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(X_text_train, y_text_train, epochs=10, batch_size=32, validation_data=(X_text_test, y_text_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_humor = mean_absolute_error(y_text_test['humour'], predictions[:, 0])\n",
    "mae_sarcasm = mean_absolute_error(y_text_test['sarcasm'], predictions[:, 1])\n",
    "mae_offense = mean_absolute_error(y_text_test['offensive'], predictions[:, 2])\n",
    "mae_motivation = mean_absolute_error(y_text_test['motivational'], predictions[:, 3])\n",
    "\n",
    "print(f\"MAE for Humor: {mae_humor}\")\n",
    "print(f\"MAE for Sarcasm: {mae_sarcasm}\")\n",
    "print(f\"MAE for Offense: {mae_offense}\")\n",
    "print(f\"MAE for Motivation: {mae_motivation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_humor = predictions[:, 0]\n",
    "predicted_sarcasm = predictions[:, 1]\n",
    "predicted_offense = predictions[:, 2]\n",
    "predicted_motivation = predictions[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted humor:\", predicted_humor[0])\n",
    "print(\"Predicted sarcasm:\", predicted_sarcasm[0])\n",
    "print(\"Predicted offense:\", predicted_offense[0])\n",
    "print(\"Predicted motivation:\", predicted_motivation[0])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 531544,
     "sourceId": 973292,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
